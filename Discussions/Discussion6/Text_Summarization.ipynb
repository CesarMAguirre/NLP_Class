{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5 - Discussion 6 \n",
    "## Text Sumarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Text:\n",
      "xAI In Talks To Raise $10BNew ThreadCtrlIHomeDiscoverSpaces  Library  cesaraguirreSOPA Images · gettyimages.comIntroductionIntroductionxAI's $10B Funding RoundxAI's $10B Funding RoundxAI's Previous Funding RoundsxAI's Previous Funding RoundsGrok-3 Launch DetailsGrok-3 Launch Details xAI In Talks To Raise $10BCurated bykakarrot3 min read5,800392According to Bloomberg, Elon Musk's artificial intelligence startup xAI is reportedly in discussions to raise $10 billion in a new funding round, potentially valuing the company at an impressive $75 billion as it seeks to strengthen its position in the highly competitive AI industry.Elon Musk's xAI Targets $75B Valuation With Potential $10B Capital Raise, Report SaysinvestopediaElon Musk’s xAI Is Seeking to Raise $10B at $75B Valuationmarkets.businessinsiderElon Musk's xAI Eyes $10 Billion Funding Round at $75 ... - Ainvestainvest+9 sources xAI's $10B Funding RoundxAI's potential $10 billion funding round represents a significant milestone in the company's rapid growth trajectory. This latest round, if successful, would value Elon Musk's AI venture at an impressive $75 billion, up from its previous $51 billion valuation12. The talks involve existing investors such as Sequoia Capital, Andreessen Horowitz, and Valor Equity Partners, signaling continued confidence in xAI's vision and potential3. While the terms are still being negotiated, this substantial capital injection is expected to fuel xAI's ambitious plans, including the purchase of over $5 billion worth of Dell servers powered by Nvidia GB200 chips to support its AI model development1. This move underscores xAI's commitment to scaling its infrastructure and maintaining its competitive edge in the fast-evolving AI landscape.3 sources xAI's Previous Funding RoundsxAI's rapid fundraising trajectory highlights the intense investor interest in AI development. The company raised $6 billion in a Series B round in May 2024, valuing it at $24 billion12. This was followed by another $6 billion round in December 2024, bringing the total raised to $12 billion3. The current $10 billion round under discussion would mark a significant leap, potentially valuing xAI at $75 billion4. This aggressive fundraising strategy reflects xAI's ambition to compete with established AI giants and accelerate its product development, including the advancement of its Grok AI model series and the construction of advanced AI infrastructure56.6 sources Grok-3 Launch Detailstechcrunch.comThe upcoming release of Grok-3, xAI's latest AI model, is closely tied to the company's ambitious funding efforts. Elon Musk has announced that Grok-3 is in its final stages of development and is expected to launch within weeks12. This new iteration is reportedly \"scary smart\" and outperforms all existing AI models in reasoning tests1. The substantial funding sought by xAI is likely to support the infrastructure needed for Grok-3's deployment and further development.\n",
      "Key features of Grok-3 include:\n",
      "\n",
      "\n",
      "Training on synthetic data for enhanced reasoning capabilities1\n",
      "\n",
      "\n",
      "Ability to analyze its own mistakes and improve accuracy1\n",
      "\n",
      "\n",
      "Integration with the X platform for real-time information processing3\n",
      "\n",
      "\n",
      "Development using 10 times more computational power than its predecessor1\n",
      "\n",
      "\n",
      "Trained at xAI's Memphis data center, housing around 200,000 GPUs14\n",
      "\n",
      "\n",
      "The release of Grok-3 is expected to strengthen xAI's position in the competitive AI market and potentially justify the high valuation sought in the current funding round.4 sourcesRelatedWhat specific advancements does Grok 3 bring over Grok 2How does Grok 3's synthetic data training improve its performanceWhat are the potential real-world applications of Grok 3How does Grok 3's reasoning capability compare to OpenAI's GPT-5What are the potential ethical concerns with Grok 3's enhanced capabilitiesKeep ReadingMusk Builds AI Compute GigafactoryElon Musk's AI startup, xAI, is embarking on an ambitious project to construct a massive supercomputer, dubbed the \"Gigafactory of Compute,\" to power the next generation of its conversational AI, Grok. This endeavor aims to significantly enhance Grok's capabilities by leveraging an unprecedented assembly of 100,000 specialized semiconductors, positioning xAI at the forefront of the AI revolution.76,001xAI Doubles ValuationElon Musk's artificial intelligence startup xAI has successfully raised $5 billion, increasing its valuation to $45 billion and nearly doubling its worth in a short period, as confirmed by insiders. This substantial growth aligns with Musk's vision and positions xAI among the most valuable AI startups in the United States, drawing significant investment interest from Middle Eastern sovereign funds and other notable backers.22,264xAI To Launch Grok 3 SoonAccording to Elon Musk, Grok 3, the latest iteration of xAI's artificial intelligence chatbot, is in its final stages of development and set to be released within the next two weeks, with claims of outperforming all rival chatbots in tests conducted so far.9,736Musk Claims Grok 3 Outperforms All RivalsElon Musk has announced that Grok 3, xAI's latest AI chatbot, will launch within weeks, claiming it surpasses all existing models in reasoning capabilities. Developed using synthetic data and powered by xAI's massive Memphis data center, Grok 3 introduces advanced features like real-time information access and an \"unhinged mode,\" but faces market challenges and controversy, including the recent resignation of an xAI engineer over a confidentiality dispute.42,804ProStopAdd SectionHomeDiscoverSpaces  Library  HomeDiscoverSpaces  Library  \n"
     ]
    }
   ],
   "source": [
    "# Let's read our HTML file and extract the text from it using BeautifulSoup\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def read_html_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            html_content = file.read()\n",
    "            return html_content\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read file: {e}\")\n",
    "        return None\n",
    "\n",
    "file_path = r\"C:\\\\BC\\\\SP_25\\\\NLP\\\\Discussions\\\\Discussion6\\\\xAI_In_Talks_To_Raise_10B.html\"\n",
    "html_content = read_html_file(file_path)\n",
    "\n",
    "if html_content:\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    article_text = soup.get_text()\n",
    "    print(\"Article Text:\")\n",
    "    print(article_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Ensure nltk data is downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Tokenize sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    # Tokenize words and preprocess\n",
    "    preprocessed_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence.lower())\n",
    "        words = [lemmatizer.lemmatize(word) for word in words if word.isalpha() and word not in stop_words]\n",
    "        preprocessed_sentence = ' '.join(words)\n",
    "        preprocessed_sentences.append(preprocessed_sentence)\n",
    "    return preprocessed_sentences\n",
    "\n",
    "preprocess_sentences = preprocess_text(article_text)\n",
    "print(f\"\\nPreprocessed Text:{preprocess_sentences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NLTK and Sumy Summary: xAI In Talks To Raise $10BNew ThreadCtrlIHomeDiscoverSpaces  Library  cesaraguirreSOPA Images · gettyimages.comIntroductionIntroductionxAI's $10B Funding RoundxAI's $10B Funding RoundxAI's Previous Funding RoundsxAI's Previous Funding RoundsGrok-3 Launch DetailsGrok-3 Launch Details xAI In Talks To Raise $10BCurated bykakarrot3 min read5,800392According to Bloomberg, Elon Musk's artificial intelligence startup xAI is reportedly in discussions to raise $10 billion in a new funding round, potentially valuing the company at an impressive $75 billion as it seeks to strengthen its position in the highly competitive AI industry.Elon Musk's xAI Targets $75B Valuation With Potential $10B Capital Raise, Report SaysinvestopediaElon Musk’s xAI Is Seeking to Raise $10B at $75B Valuationmarkets.businessinsiderElon Musk's xAI Eyes $10 Billion Funding Round at $75 ... - Ainvestainvest+9 sources xAI's $10B Funding RoundxAI's potential $10 billion funding round represents a significant milestone in the company's rapid growth trajectory.This substantial growth aligns with Musk's vision and positions xAI among the most valuable AI startups in the United States, drawing significant investment interest from Middle Eastern sovereign funds and other notable backers.22,264xAI To Launch Grok 3 SoonAccording to Elon Musk, Grok 3, the latest iteration of xAI's artificial intelligence chatbot, is in its final stages of development and set to be released within the next two weeks, with claims of outperforming all rival chatbots in tests conducted so far.9,736Musk Claims Grok 3 Outperforms All RivalsElon Musk has announced that Grok 3, xAI's latest AI chatbot, will launch within weeks, claiming it surpasses all existing models in reasoning capabilities.Developed using synthetic data and powered by xAI's massive Memphis data center, Grok 3 introduces advanced features like real-time information access and an \"unhinged mode,\" but faces market challenges and controversy, including the recent resignation of an xAI engineer over a confidentiality dispute.42,804ProStopAdd SectionHomeDiscoverSpaces  Library  HomeDiscoverSpaces  Library\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "\n",
    "def summarize_nltk_sumy(text, num_sentences):\n",
    "    \n",
    "    # Summarize using Sumy\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer('english'))\n",
    "    summarizer = LexRankSummarizer()\n",
    "    summary = summarizer(parser.document, num_sentences)\n",
    "    return \"\".join([str(sentence) for sentence in summary])\n",
    "\n",
    "# Let's use the original article text for this method\n",
    "summarize_nltk_sumy = summarize_nltk_sumy(article_text, 3)\n",
    "\n",
    "print(f\"\\nNLTK and Sumy Summary: {summarize_nltk_sumy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\18126\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\18126\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a0e26e522c423d826a466fac4d56f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\18126\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\18126\\.cache\\huggingface\\hub\\models--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4270682a14a44112b87c20dd7c79a9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c918af5ac55e4491a58f4625216d20e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1309 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformers Summary: xAI is reportedly in talks to raise $10 billion in a new funding round. if successful, the company would value Elon Musk's AI venture at an impressive $75 billion, up from its previous $51 billion valuation 12 years ago. this move underscores the intense investor interest in AI development, including the purchase of over $5 billion worth of Dell servers powered by Nvidia GB200 chips.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "def summarize_transformers(text):\n",
    "    model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "    tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "    input_text = \"summarize: \" + text\n",
    "    inputs = tokenizer(input_text, return_tensors='pt')\n",
    "\n",
    "    outputs = model.generate(inputs[\"input_ids\"], num_beams = 5, no_repeat_ngram_size = 2, min_length = 30, max_length = 100, early_stopping = True)\n",
    "\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Let's use the orgiinal text for this method\n",
    "summary_transformers = summarize_transformers(article_text)\n",
    "print(f\"\\nTransformers Summary: {summary_transformers}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
